{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "For those of you who haven't used notebooks like this before, they provide a convenient way to do exploratory data science work in a format that combines your code and its output in an easy-to-share way. Above, you will see a dropdown menu that allows you to switch a cell in the notebook between code and markdown text (like here).\n",
    "\n",
    "To create a new cell below your current position, press the + button above. To run the code in a cell, or render your markdown text, press Shift+Enter.\n",
    "\n",
    "To begin, we import a couple python libraries we'll need throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data using pd.read_csv(), supplying the path to the data.\n",
    "\n",
    "Inspect the first few rows of your data frame using the .head() method, supplying n=10 as an argument to show the top 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>directed_at</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW Wi...</td>\n",
       "      <td>Android App</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X                                         tweet_text         directed_at  \\\n",
       "0   1  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1   3  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "2   5  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "3   6  @teachntech00 New iPad Apps For #SpeechTherapy...                 NaN   \n",
       "4   7                                                NaN                 NaN   \n",
       "5   8  #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "6   9  Beautifully smart and simple idea RT @madebyma...  iPad or iPhone App   \n",
       "7  10  Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "8  11  Excited to meet the @samsungmobileus at #sxsw ...             Android   \n",
       "9  12  Find &amp; Start Impromptu Parties at #SXSW Wi...         Android App   \n",
       "\n",
       "  tweet_sentiment  \n",
       "0        negative  \n",
       "1        positive  \n",
       "2        positive  \n",
       "3         neutral  \n",
       "4             NaN  \n",
       "5        positive  \n",
       "6        positive  \n",
       "7        positive  \n",
       "8        positive  \n",
       "9        positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('tweets.csv')\n",
    "tweets.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's a problem -- we have some missing data. Let's remove lines in our data that don't contain a tweet.\n",
    "\n",
    "Pandas makes this easy with the notnull() function. Take note of how Pandas makes use of square brackets to identify an individual column of that data frame.\n",
    "\n",
    "Then, verify that the missing rows have been properly excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets[pd.notnull(tweets['tweet_text'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are three columns of data here, but for now let's limit ourselves to tweet_text and tweet_sentiment. \n",
    "\n",
    "Assign each of these columns to new variables called \"text\" and \"labels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = tweets['tweet_text']\n",
    "labels = tweets['tweet_sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning our text into numbers\n",
    "\n",
    "Regardless of the data you're using, machine learning is always a mathematical task. That means we have to convert our raw text into a usable format -- in this case, counts of word occurrences. This next step also makes our first use of the scikit-learn ML library.\n",
    "\n",
    "Take the CountVectorizer instance created below and apply it to the text of your tweets using the .fit() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the fitted CountVectorizer object look like?\n",
    "\n",
    "Fitting count_vect to our data produces a matrix where the rows are tweets, and the columns represent every word in our \"vocabulary\" (i.e., our whole set of tweets). The first step in this is to figure out what those matrix dimensions will be. Check out the vocabulary&#95; object -- it is a mapping from vocabulary words to matrix columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'unscientific': 8943,\n",
       " u'hordes': 4133,\n",
       " u'pickmeupanipad2': 6313,\n",
       " u'yellow': 9505,\n",
       " u'four': 3400,\n",
       " u'prices': 6576,\n",
       " u'woods': 9399,\n",
       " u'hanging': 3903,\n",
       " u'16mins': 70,\n",
       " u'increase': 4348,\n",
       " u'html5': 4173,\n",
       " u'gad': 3509,\n",
       " u'eligible': 2815,\n",
       " u'gadgetoverload': 3512,\n",
       " u'lori': 5099,\n",
       " u'sxswdad': 8244,\n",
       " u'lord': 5097,\n",
       " u'newmusic': 5744,\n",
       " u'withme': 9370,\n",
       " u'bergstrom': 1059,\n",
       " u'dell': 2327,\n",
       " u'rancewilemon': 6811,\n",
       " u'leisurely': 4932,\n",
       " u'bringing': 1296,\n",
       " u'basics': 966,\n",
       " u'prize': 6599,\n",
       " u'customizable': 2190,\n",
       " u'wednesday': 9254,\n",
       " u'oooh': 5961,\n",
       " u'debuting': 2281,\n",
       " u'commented': 1825,\n",
       " u'smscifi': 7734,\n",
       " u'tired': 8590,\n",
       " u'miller': 5446,\n",
       " u'cpmpetition': 2074,\n",
       " u'pulse': 6693,\n",
       " u'270': 116,\n",
       " u'elegant': 2810,\n",
       " u'second': 7380,\n",
       " u'tether': 8444,\n",
       " u'penasaran': 6229,\n",
       " u'errors': 2928,\n",
       " u'unlisted': 8924,\n",
       " u'roddy': 7175,\n",
       " u'thunder': 8548,\n",
       " u'fingers': 3252,\n",
       " u'designing': 2368,\n",
       " u'succumb': 8116,\n",
       " u'reword_app': 7102,\n",
       " u'hero': 4015,\n",
       " u'dahl': 2210,\n",
       " u'reporter': 7021,\n",
       " u'freebeernear': 3421,\n",
       " u'leaning': 4905,\n",
       " u'brainwashed': 1254,\n",
       " u'here': 4013,\n",
       " u'jon': 4660,\n",
       " u'reported': 7019,\n",
       " u'china': 1645,\n",
       " u'smartcover': 7704,\n",
       " u'cult': 2165,\n",
       " u'affiliated': 420,\n",
       " u'futurecast': 3495,\n",
       " u'dork': 2597,\n",
       " u'buddy': 1339,\n",
       " u'geoloqi': 3606,\n",
       " u'kids': 4755,\n",
       " u'reports': 7023,\n",
       " u'oxymoron': 6078,\n",
       " u'circumferences': 1686,\n",
       " u'iphoneapp': 4528,\n",
       " u'military': 5443,\n",
       " u'criticism': 2129,\n",
       " u'golden': 3691,\n",
       " u'divide': 2524,\n",
       " u'magically': 5190,\n",
       " u'wikimedia': 9326,\n",
       " u'sters': 8009,\n",
       " u'replace': 7011,\n",
       " u'brought': 1313,\n",
       " u'hahahahah': 3875,\n",
       " u'sxwonderful': 8278,\n",
       " u'txt': 8842,\n",
       " u'monetization': 5540,\n",
       " u'spoke': 7907,\n",
       " u'browse': 1315,\n",
       " u'lenewz': 4937,\n",
       " u'symphony': 8285,\n",
       " u'music': 5618,\n",
       " u'therefore': 8499,\n",
       " u'passport': 6173,\n",
       " u'strike': 8070,\n",
       " u'musik': 5626,\n",
       " u'until': 8947,\n",
       " u'holy': 4093,\n",
       " u'relax': 6970,\n",
       " u'successful': 8114,\n",
       " u'brings': 1297,\n",
       " u'yahoo': 9490,\n",
       " u'hurt': 4197,\n",
       " u'99': 288,\n",
       " u'glass': 3652,\n",
       " u'90': 277,\n",
       " u'hole': 4085,\n",
       " u'hold': 4082,\n",
       " u'95': 283,\n",
       " u'sorry': 7832,\n",
       " u'97': 286,\n",
       " u'96': 284,\n",
       " u'locked': 5060,\n",
       " u'x6t1pi6av7': 9474,\n",
       " u'temperatures': 8418,\n",
       " u'zomg': 9586,\n",
       " u'example': 2997,\n",
       " u'bizzy': 1123,\n",
       " u'wellplayed': 9266,\n",
       " u'hyatt': 4203,\n",
       " u'organized': 6007,\n",
       " u'wanw': 9190,\n",
       " u'want': 9185,\n",
       " u'organizer': 6008,\n",
       " u'elitebook': 2816,\n",
       " u'rewardswagon': 7100,\n",
       " u'absolute': 313,\n",
       " u'merissa': 5395,\n",
       " u'hoc': 4079,\n",
       " u'knows': 4801,\n",
       " u'turn': 8801,\n",
       " u'hoo': 4108,\n",
       " u'travel': 8714,\n",
       " u'h0u5t0n': 3848,\n",
       " u'feature': 3166,\n",
       " u'machine': 5169,\n",
       " u'how': 4157,\n",
       " u'hot': 4142,\n",
       " u'playback': 6381,\n",
       " u'hop': 4124,\n",
       " u'place': 6358,\n",
       " u'chase': 1596,\n",
       " u'wolfram': 9389,\n",
       " u'gaming': 3536,\n",
       " u'cabbie': 1412,\n",
       " u'beauty': 1012,\n",
       " u'misunderstanding': 5489,\n",
       " u'diagram': 2411,\n",
       " u'wrong': 9459,\n",
       " u'willinclude': 9335,\n",
       " u'nonprofit': 5800,\n",
       " u'types': 8847,\n",
       " u'effective': 2782,\n",
       " u'occasions': 5899,\n",
       " u'wins': 9353,\n",
       " u'revolt': 7094,\n",
       " u'creepily': 2116,\n",
       " u'cigarettes': 1679,\n",
       " u'w2p': 9146,\n",
       " u'keeps': 4722,\n",
       " u'swsurrogates': 8215,\n",
       " u'wine': 9347,\n",
       " u'feedback': 3179,\n",
       " u'guykawasaki': 3842,\n",
       " u'californians': 1428,\n",
       " u'fit': 3270,\n",
       " u'rankings': 6820,\n",
       " u'fix': 3279,\n",
       " u'striking': 8072,\n",
       " u'qualcosa': 6740,\n",
       " u'hidden': 4028,\n",
       " u'fin': 3236,\n",
       " u'easier': 2738,\n",
       " u'slate': 7666,\n",
       " u'recollections': 6897,\n",
       " u'effects': 2784,\n",
       " u'tvontheradio': 8810,\n",
       " u'schools': 7329,\n",
       " u'jetlag': 4633,\n",
       " u'silver': 7597,\n",
       " u'rumour': 7219,\n",
       " u'debut': 2280,\n",
       " u'barton': 958,\n",
       " u'lockout': 5062,\n",
       " u'arrow': 726,\n",
       " u'addicted': 375,\n",
       " u'directly': 2462,\n",
       " u'woes': 9385,\n",
       " u'knockout': 4795,\n",
       " u'spider': 7892,\n",
       " u'solution': 7806,\n",
       " u'2day': 121,\n",
       " u'mdw': 5325,\n",
       " u'rt': 7207,\n",
       " u'trending': 8730,\n",
       " u'smx': 7742,\n",
       " u'dst': 2675,\n",
       " u'sms': 7733,\n",
       " u'ry': 7229,\n",
       " u're': 6833,\n",
       " u'encourage': 2858,\n",
       " u'rg': 7105,\n",
       " u'nfusion': 5762,\n",
       " u'rm': 7155,\n",
       " u'engineer': 2875,\n",
       " u'smc': 7714,\n",
       " u'ischafer': 4550,\n",
       " u'peterapokotos': 6278,\n",
       " u'fludapp': 3322,\n",
       " u'corrects': 2031,\n",
       " u'sensors': 7420,\n",
       " u'ate': 772,\n",
       " u'exposing': 3059,\n",
       " u'shelves': 7503,\n",
       " u'atl': 773,\n",
       " u'sm2': 7694,\n",
       " u'festivalexplorer': 3202,\n",
       " u'liebling': 4970,\n",
       " u'shipped': 7519,\n",
       " u'musicians': 5621,\n",
       " u'tempting': 8424,\n",
       " u'clothes': 1741,\n",
       " u'resetting': 7041,\n",
       " u'atx': 798,\n",
       " u'dodgeball': 2550,\n",
       " u'lazers': 4889,\n",
       " u'dailies': 2211,\n",
       " u'channels': 1578,\n",
       " u'spinning': 7899,\n",
       " u'customization': 2191,\n",
       " u'wasn': 9203,\n",
       " u'f\\xfcr': 3504,\n",
       " u'lucys': 5138,\n",
       " u'sweeeet': 8195,\n",
       " u'service': 7438,\n",
       " u'lego': 4927,\n",
       " u'engagement': 2872,\n",
       " u'needed': 5704,\n",
       " u'master': 5289,\n",
       " u'listed': 5019,\n",
       " u'chugging': 1671,\n",
       " u'apple2': 654,\n",
       " u'bitter': 1118,\n",
       " u'listen': 5020,\n",
       " u'rewards': 7099,\n",
       " u'iphonedev': 4529,\n",
       " u'cocktails': 1778,\n",
       " u'sacca': 7235,\n",
       " u'task': 8346,\n",
       " u'palsy': 6115,\n",
       " u'scarborough': 7303,\n",
       " u'positively': 6476,\n",
       " u'trek': 8726,\n",
       " u'showed': 7559,\n",
       " u'tree': 8724,\n",
       " u'craigslistkiller': 2083,\n",
       " u'project': 6628,\n",
       " u'mkesxsw': 5496,\n",
       " u'idle': 4253,\n",
       " u'hacknews': 3866,\n",
       " u'feeling': 3184,\n",
       " u'acquisition': 349,\n",
       " u'boston': 1221,\n",
       " u'aapl': 298,\n",
       " u'engadget': 2869,\n",
       " u'alive': 501,\n",
       " u'cesar': 1558,\n",
       " u'releases': 6976,\n",
       " u'regretting': 6956,\n",
       " u'pushsxsw11': 6718,\n",
       " u'eagerly': 2720,\n",
       " u'recommended': 6902,\n",
       " u'causing': 1521,\n",
       " u'amusing': 562,\n",
       " u'doors': 2595,\n",
       " u'season': 7373,\n",
       " u'shipments': 7518,\n",
       " u'shall': 7475,\n",
       " u'thrilled': 8536,\n",
       " u'object': 5881,\n",
       " u'metrics': 5410,\n",
       " u'swiss': 8207,\n",
       " u'mouth': 5580,\n",
       " u'addict': 374,\n",
       " u'letter': 4954,\n",
       " u'entry': 2902,\n",
       " u'dugan': 2691,\n",
       " u'macbook': 5165,\n",
       " u'episode': 2919,\n",
       " u'aproveitem': 691,\n",
       " u'cops': 2007,\n",
       " u'camp': 1443,\n",
       " u'tech': 8381,\n",
       " u'scream': 7347,\n",
       " u'came': 1439,\n",
       " u'evolvingworkplace': 2988,\n",
       " u'plutopia': 6410,\n",
       " u'saying': 7291,\n",
       " u'condesa': 1886,\n",
       " u'bomb': 1189,\n",
       " u'meetings': 5354,\n",
       " u'participate': 6154,\n",
       " u'tempted': 8423,\n",
       " u'lessons': 4948,\n",
       " u'busy': 1382,\n",
       " u'clicked': 1721,\n",
       " u'shuffling': 7569,\n",
       " u'headline': 3969,\n",
       " u'edtech': 2772,\n",
       " u'699': 240,\n",
       " u'bust': 1380,\n",
       " u'than': 8455,\n",
       " u'theme': 8486,\n",
       " u'bliss': 1144,\n",
       " u'touched': 8660,\n",
       " u'rich': 7111,\n",
       " u'bitbop': 1115,\n",
       " u'lady': 4823,\n",
       " u'plate': 6377,\n",
       " u'trackpads': 8682,\n",
       " u'pocket': 6416,\n",
       " u'id420666439': 4240,\n",
       " u'tips': 8589,\n",
       " u'vicariously': 9075,\n",
       " u'autistic': 835,\n",
       " u'nicely': 5765,\n",
       " u'ever': 2972,\n",
       " u'akabuzz': 476,\n",
       " u'patch': 6177,\n",
       " u'release': 6974,\n",
       " u'boarded': 1177,\n",
       " u'sqft': 7933,\n",
       " u'blew': 1141,\n",
       " u'leasing': 4915,\n",
       " u'disaster': 2473,\n",
       " u'fair': 3105,\n",
       " u'evolving': 2987,\n",
       " u'unexpectedly': 8910,\n",
       " u'9abc': 289,\n",
       " u'radius': 6789,\n",
       " u'result': 7064,\n",
       " u'fail': 3101,\n",
       " u'skulls': 7658,\n",
       " u'best': 1066,\n",
       " u'benieuwd': 1056,\n",
       " u'lots': 5106,\n",
       " u'rings': 7139,\n",
       " u'ringo': 7138,\n",
       " u'stamps': 7955,\n",
       " u'score': 7339,\n",
       " u'irl': 4542,\n",
       " u'melissa': 5366,\n",
       " u'conceptual': 1876,\n",
       " u'4hb': 197,\n",
       " u'alguien': 495,\n",
       " u'never': 5735,\n",
       " u'extend': 3063,\n",
       " u'rolled': 7179,\n",
       " u'conflagration': 1898,\n",
       " u'wth': 9466,\n",
       " u'carbon': 1473,\n",
       " u'marc_is_ken': 5244,\n",
       " u'pity': 6350,\n",
       " u'patented': 6178,\n",
       " u'planner': 6370,\n",
       " u'sxswmusic': 8262,\n",
       " u'country': 2049,\n",
       " u'sxsw4jp': 8233,\n",
       " u'heating': 3987,\n",
       " u'newtwitter': 5754,\n",
       " u'planned': 6369,\n",
       " u'lookin': 5087,\n",
       " u'logic': 5066,\n",
       " u'garageband': 3541,\n",
       " u'login': 5068,\n",
       " u'asked': 753,\n",
       " u'30th': 144,\n",
       " u'imp1000': 4298,\n",
       " u'groupon': 3797,\n",
       " u'2nd': 126,\n",
       " u'lanzamiento': 4840,\n",
       " u'electricnews': 2808,\n",
       " u'diff': 2430,\n",
       " u'250': 111,\n",
       " u'smackdown': 7696,\n",
       " u'pensei': 6237,\n",
       " u'angel': 581,\n",
       " u'billing': 1099,\n",
       " u'chrome': 1666,\n",
       " u'bitrate': 1117,\n",
       " u'fri': 3431,\n",
       " u'frm': 3446,\n",
       " u'much': 5603,\n",
       " u'life': 4972,\n",
       " u'sosososo': 7837,\n",
       " u'lift': 4977,\n",
       " u'digitalluxury': 2444,\n",
       " u'child': 1633,\n",
       " u'worked': 9411,\n",
       " u'spin': 7898,\n",
       " u'chill': 1638,\n",
       " u'commerce': 1827,\n",
       " u'2wks': 131,\n",
       " u'meetin': 5352,\n",
       " u'droppin': 2660,\n",
       " u'unloading': 8926,\n",
       " u'flooding': 3314,\n",
       " u'rebeltv': 6873,\n",
       " u'bin': 1104,\n",
       " u'congratulation': 1905,\n",
       " u'played': 6383,\n",
       " u'toolkit': 8634,\n",
       " u'player': 6384,\n",
       " u'piercings': 6326,\n",
       " u'violin': 9092,\n",
       " u'insatiable': 4414,\n",
       " u'trusted': 8765,\n",
       " u'severity': 7459,\n",
       " u'things': 8511,\n",
       " u'any': 615,\n",
       " u'tweetcaster': 8817,\n",
       " u'craigslist': 2082,\n",
       " u'olderadults': 5929,\n",
       " u'split': 7905,\n",
       " u'babies': 887,\n",
       " u'elliott': 2818,\n",
       " u'gr2l2': 3746,\n",
       " u'couple': 2051,\n",
       " u'foosspotting': 3363,\n",
       " u'fastcompanygrille': 3145,\n",
       " u'tops': 8645,\n",
       " u'whrrl': 9312,\n",
       " u'tune': 8795,\n",
       " u'nuanced': 5859,\n",
       " u'scoremore': 7341,\n",
       " u'spearheading': 7872,\n",
       " u'corporate': 2021,\n",
       " u'opinions': 5979,\n",
       " u'booyah': 1210,\n",
       " u'capitol': 1464,\n",
       " u'wjchat': 9376,\n",
       " u'dtas': 2677,\n",
       " u'fantastic': 3125,\n",
       " u'homogeneity': 4102,\n",
       " u'financially': 3244,\n",
       " u'ctia': 2160,\n",
       " u'hah': 3871,\n",
       " u'wandered': 9179,\n",
       " u'imacs': 4282,\n",
       " u'had': 3869,\n",
       " u'haz': 3954,\n",
       " u'kickoffparty': 4748,\n",
       " u'collections': 1802,\n",
       " u'easy': 2742,\n",
       " u'has': 3928,\n",
       " u'elevation': 2813,\n",
       " u'casually': 1508,\n",
       " u'1154': 24,\n",
       " u'survival': 8178,\n",
       " u'posed': 6471,\n",
       " u'possible': 6481,\n",
       " u'stds': 7993,\n",
       " u'possibly': 6482,\n",
       " u'alwayshavingtoplugin': 532,\n",
       " u'birth': 1111,\n",
       " u'unique': 8916,\n",
       " u'rainjacket': 6801,\n",
       " u'desire': 2370,\n",
       " u'anticipation': 608,\n",
       " u'bobby': 1180,\n",
       " u'alice': 496,\n",
       " u'champ': 1569,\n",
       " u'festivities': 3204,\n",
       " u'smvis': 7741,\n",
       " u'steps': 8006,\n",
       " u'bizgym': 1121,\n",
       " u'googleio': 3717,\n",
       " u'right': 7129,\n",
       " u'old': 5927,\n",
       " u'creek': 2114,\n",
       " u'crowd': 2138,\n",
       " u'people': 6239,\n",
       " u'begin': 1031,\n",
       " u'captive': 1467,\n",
       " u'sure': 8163,\n",
       " u'yoroshiku': 9522,\n",
       " u'gasps': 3546,\n",
       " u'cocaine': 1776,\n",
       " u'attendees': 785,\n",
       " u'for': 3367,\n",
       " u'bottom': 1228,\n",
       " u'creative': 2106,\n",
       " u'witty': 9375,\n",
       " u'when': 9285,\n",
       " u'continue': 1960,\n",
       " u'umm': 8877,\n",
       " u'htdfim': 4171,\n",
       " u'mpact': 5591,\n",
       " u'unequipped': 8908,\n",
       " u'sadpanda': 7239,\n",
       " u'barcode': 946,\n",
       " u'shifting': 7510,\n",
       " u'sxswsa': 8272,\n",
       " u'starring': 7964,\n",
       " u'mcgraw': 5322,\n",
       " u'losing': 5103,\n",
       " u'manufacturing': 5230,\n",
       " u'marketers': 5261,\n",
       " u'visitors': 9108,\n",
       " u'nowplaying': 5851,\n",
       " u'dollars': 2566,\n",
       " u'crapkit': 2085,\n",
       " u'mocking': 5520,\n",
       " u'joomla': 4664,\n",
       " u'stoked': 8024,\n",
       " u'niran': 5787,\n",
       " u'slightly': 7679,\n",
       " u'raised': 6803,\n",
       " u'statements': 7979,\n",
       " u'marshall': 5269,\n",
       " u'spontaniety': 7912,\n",
       " u'inspiredbyprint': 4426,\n",
       " u'soo': 7826,\n",
       " u'presenters': 6557,\n",
       " u'juicing': 4687,\n",
       " u'magazines': 5185,\n",
       " u'raises': 6804,\n",
       " u'wrap': 9446,\n",
       " u'shoots': 7533,\n",
       " u'mbp': 5319,\n",
       " u'cleared': 1715,\n",
       " u'panorama': 6126,\n",
       " u'support': 8157,\n",
       " u'constantly': 1934,\n",
       " u'360idev': 159,\n",
       " u'avail': 849,\n",
       " u'absolutely': 314,\n",
       " u'wordpress': 9407,\n",
       " u'goddamn': 3676,\n",
       " u'call': 1429,\n",
       " u'halls': 3886,\n",
       " u'launching': 4873,\n",
       " u'happy': 3913,\n",
       " u'offer': 5905,\n",
       " u'forming': 3388,\n",
       " u'paypal': 6200,\n",
       " u'notifications': 5833,\n",
       " u'pagerank': 6096,\n",
       " u'imthatgood': 4327,\n",
       " u'fiting': 3271,\n",
       " u'mymom': 5640,\n",
       " u'_and_': 294,\n",
       " u'congratulations': 1906,\n",
       " u'inside': 4416,\n",
       " u'myopia': 5641,\n",
       " u'devices': 2401,\n",
       " u'considered': 1925,\n",
       " u'smashed': 7713,\n",
       " u'panels': 6121,\n",
       " u'150': 56,\n",
       " u'looms': 5091,\n",
       " u'disgrace': 2493,\n",
       " u'palo': 6113,\n",
       " u'qik': 6731,\n",
       " u'implications': 4308,\n",
       " u'tournament': 8668,\n",
       " u'livestrong': 5036,\n",
       " u'proven': 6660,\n",
       " u'somebody': 7813,\n",
       " u'zimride': 9576,\n",
       " u'exist': 3021,\n",
       " u'relay': 6973,\n",
       " u'floor': 3315,\n",
       " u'flood': 3312,\n",
       " u'republic': 7028,\n",
       " u'dtsxsw': 2679,\n",
       " u'developers': 2396,\n",
       " u'smell': 7719,\n",
       " u'roll': 7178,\n",
       " u'models': 5523,\n",
       " u'cluttering': 1755,\n",
       " u'smelling': 7720,\n",
       " u'rolling': 7181,\n",
       " u'penneys': 6235,\n",
       " u'15k': 62,\n",
       " u'waffle': 9153,\n",
       " u'nxt': 5873,\n",
       " u'98': 287,\n",
       " u'time': 8570,\n",
       " u'push': 6713,\n",
       " u'ipadmadness': 4521,\n",
       " u'debate': 2277,\n",
       " u'osx': 6020,\n",
       " u'minimalistprogramming': 5466,\n",
       " u'newbie': 5740,\n",
       " u'chain': 1562,\n",
       " u'cuteeeeee': 2195,\n",
       " u'cicles': 1677,\n",
       " u'skiing': 7648,\n",
       " u'imthetype': 4328,\n",
       " u'midst': 5433,\n",
       " u'ware': 9192,\n",
       " u'baller': 919,\n",
       " u'unpack': 8936,\n",
       " u'babalola': 886,\n",
       " u'samsungsxsw': 7260,\n",
       " u'sloansxsw': 7683,\n",
       " u'speakeasy': 7866,\n",
       " u'sneakers': 7757,\n",
       " u'812': 261,\n",
       " u'veterans': 9068,\n",
       " u'downloading': 2620,\n",
       " u'jerk': 4628,\n",
       " u'hangover3': 3905,\n",
       " u'cheap': 1603,\n",
       " u'choice': 1651,\n",
       " u'alcoholics': 490,\n",
       " u'klout': 4785,\n",
       " u'stays': 7992,\n",
       " u'southpaw': 7851,\n",
       " u'exact': 2995,\n",
       " u'w00t': 9145,\n",
       " u'minute': 5473,\n",
       " u'hnwsxsw': 4075,\n",
       " u'solves': 7810,\n",
       " u'amoral': 556,\n",
       " u'skewed': 7643,\n",
       " u'leave': 4918,\n",
       " u'solved': 7809,\n",
       " u'settle': 7453,\n",
       " u'team': 8372,\n",
       " u'ver': 9052,\n",
       " u'droid': 2655,\n",
       " u'rents': 7007,\n",
       " u'sigh': 7580,\n",
       " u'sign': 7584,\n",
       " u'crescent': 2119,\n",
       " u'ocarina': 5896,\n",
       " u'jeopardy': 4626,\n",
       " u'miketyson': 5441,\n",
       " u'current': 2179,\n",
       " u'300': 135,\n",
       " u'ground': 3790,\n",
       " u'badge': 903,\n",
       " u'reword': 7101,\n",
       " u'hipstamatic': 4048,\n",
       " u'understanding': 8900,\n",
       " u'upgrade': 8964,\n",
       " u'address': 384,\n",
       " u'alone': 515,\n",
       " u'onsulting': 5954,\n",
       " u'along': 516,\n",
       " u'dwindling': 2709,\n",
       " u'thankyouecon': 8461,\n",
       " u'brilliant': 1294,\n",
       " u'impacted': 4301,\n",
       " u'vectors': 9039,\n",
       " u'queue': 6755,\n",
       " u'zaggle': 9560,\n",
       " u'studies': 8087,\n",
       " u'influx': 4383,\n",
       " u'tasks': 8347,\n",
       " u'love': 5115,\n",
       " u'prefer': 6530,\n",
       " u'logical': 5067,\n",
       " u'bloody': 1160,\n",
       " u'chromeos': 1668,\n",
       " u'fake': 3107,\n",
       " u'sxnewworlds': 8222,\n",
       " u'cocktail': 1777,\n",
       " u'working': 9414,\n",
       " u'geekbeat': 3572,\n",
       " u'positive': 6475,\n",
       " u'angry': 582,\n",
       " u'tripping': 8747,\n",
       " u'crowdsourcing': 2144,\n",
       " u'wondering': 9396,\n",
       " u'films': 3232,\n",
       " u'scope': 7337,\n",
       " u'oreilly': 6000,\n",
       " u'loving': 5127,\n",
       " u'introducing': 4487,\n",
       " u'suckas': 8120,\n",
       " u'afford': 422,\n",
       " u'apparent': 641,\n",
       " u'ip2': 4511,\n",
       " u'visual': 9111,\n",
       " u'everywhere': 2981,\n",
       " u'ip4': 4512,\n",
       " u'logos': 5070,\n",
       " u'anything': 621,\n",
       " u'originally': 6011,\n",
       " u'fastsociety': 3148,\n",
       " u'believes': 1046,\n",
       " u'values': 9025,\n",
       " u'following': 3350,\n",
       " u'detached': 2381,\n",
       " u'admired': 390,\n",
       " u'groupme': 3796,\n",
       " u'awesome': 871,\n",
       " u'parachute': 6136,\n",
       " u'locks': 5063,\n",
       " u'unveiled': 8952,\n",
       " u'230': 107,\n",
       " u'monitoring': 5546,\n",
       " u'optimas': 5985,\n",
       " u'conservebatterylife': 1922,\n",
       " u'ericschu_ras': 2926,\n",
       " u'grossed': 3789,\n",
       " u'optimal': 5984,\n",
       " u'wintel': 9354,\n",
       " u'vufinders': 9141,\n",
       " u'explorer': 3054,\n",
       " u'spot': 7915,\n",
       " u'latte': 4866,\n",
       " u'choreography': 1658,\n",
       " u'applications': 667,\n",
       " u'improving': 4323,\n",
       " u'such': 8118,\n",
       " u'suck': 8119,\n",
       " u'data': 2245,\n",
       " u'aicn': 458,\n",
       " u'stress': 8064,\n",
       " u'surfing': 8166,\n",
       " u'natural': 5684,\n",
       " u'sr': 7938,\n",
       " u'sq': 7932,\n",
       " u'quot': 6768,\n",
       " u'sw': 8186,\n",
       " u'vizthink': 9119,\n",
       " u'st': 7941,\n",
       " u'si': 7573,\n",
       " u'sh': 7468,\n",
       " u'so': 7766,\n",
       " u'sn': 7744,\n",
       " u'sm': 7693,\n",
       " u'socialemedia': 7774,\n",
       " u'pulled': 6691,\n",
       " u'sf': 7464,\n",
       " u'se': 7365,\n",
       " u'sd': 7363,\n",
       " u'drunken': 2669,\n",
       " u'tts': 8783,\n",
       " u'years': 9502,\n",
       " u'course': 2055,\n",
       " u'experiments': 3042,\n",
       " u'omitting': 5940,\n",
       " u'kanye': 4712,\n",
       " u'tore': 8649,\n",
       " u'jig': 4637,\n",
       " u'djs': 2531,\n",
       " u'solace': 7797,\n",
       " u'saysshewithoutanipad': 7293,\n",
       " u'kfn3f5q': 4738,\n",
       " u'jim': 4638,\n",
       " u'cashmore': 1504,\n",
       " u'gatorade': 3551,\n",
       " u'spotlighting': 7917,\n",
       " u'gooddeed': 3699,\n",
       " u'petition': 6279,\n",
       " u'instantly': 4434,\n",
       " u'thereby': 8498,\n",
       " u'constantcontact': 1933,\n",
       " u'smarter': 7705,\n",
       " u'evacuation': 2955,\n",
       " u'indigenous': 4363,\n",
       " u'records': 6911,\n",
       " u'arriving': 724,\n",
       " u'sorted': 7835,\n",
       " u'shhh': 7506,\n",
       " u'similarily': 7599,\n",
       " u'didn': 2421,\n",
       " u'recharged': 6886,\n",
       " u'garyvee': 3543,\n",
       " u'quarter': 6747,\n",
       " u'square': 7934,\n",
       " u'bursting': 1372,\n",
       " u'crushing': 2151,\n",
       " u'breakthrough': 1273,\n",
       " u'entering': 2891,\n",
       " u'poopin': 6441,\n",
       " u'giddy': 3628,\n",
       " u'canvas': 1458,\n",
       " u'ughhhhh': 8863,\n",
       " u'rounding': 7195,\n",
       " u'seriously': 7429,\n",
       " u'trauma': 8713,\n",
       " u'internet': 4466,\n",
       " u'formula': 3389,\n",
       " u'leanstartup': 4906,\n",
       " u'million': 5447,\n",
       " u'possibility': 6480,\n",
       " u'quite': 6766,\n",
       " u'complicated': 1865,\n",
       " u'besides': 1065,\n",
       " u'recon': 6904,\n",
       " u'dunno': 2699,\n",
       " u'spam': 7855,\n",
       " u'iterative': 4566,\n",
       " u'routed': 7199,\n",
       " u'chevy': 1624,\n",
       " u'gdgtaustin': 3562,\n",
       " u'massive': 5288,\n",
       " u'routes': 7200,\n",
       " u'furby': 3489,\n",
       " u'intuition': 4490,\n",
       " u'saving': 7284,\n",
       " u'reveals': 7087,\n",
       " u'spoken': 7908,\n",
       " u'gsdm': 3809,\n",
       " u'one': 5944,\n",
       " u'submit': 8105,\n",
       " u'spanish': 7858,\n",
       " u'vote': 9136,\n",
       " u'ons': 5950,\n",
       " u'cellbots': 1539,\n",
       " u'open': 5966,\n",
       " u'ripping': 7144,\n",
       " u'city': 1694,\n",
       " u'looong': 5092,\n",
       " u'bite': 1116,\n",
       " u'structured': 8079,\n",
       " u'guadalupe': 3816,\n",
       " u'fml': 3331,\n",
       " u'typing': 8848,\n",
       " u'iwantacameraonmyipad': 4584,\n",
       " u'latism': 4864,\n",
       " u'structures': 8080,\n",
       " u'williams': 9334,\n",
       " u'artworks': 744,\n",
       " u'shawn': 7494,\n",
       " u'cutts': 2198,\n",
       " u'proving': 6665,\n",
       " u'snatch': 7754,\n",
       " u'lamewad': 4830,\n",
       " u'ridiculous': 7121,\n",
       " u'boyfriend': 1243,\n",
       " u'warwick': 9200,\n",
       " u'bored': 1214,\n",
       " u'third': 8518,\n",
       " u'depressed': 2356,\n",
       " u'rival': 7151,\n",
       " u'exhibitors': 3020,\n",
       " u'crossroads': 2137,\n",
       " u'future': 3494,\n",
       " u'wandering': 9181,\n",
       " u'damned': 2221,\n",
       " u'san': 7261,\n",
       " u'sam': 7253,\n",
       " u'webfonts': 9238,\n",
       " u'turned': 8802,\n",
       " u'locations': 5057,\n",
       " u'alley': 505,\n",
       " u'sad': 7237,\n",
       " u'woah': 9382,\n",
       " u'tastes': 8349,\n",
       " u'buried': 1366,\n",
       " u'lurking': 5146,\n",
       " u'allen': 504,\n",
       " u'saw': 7287,\n",
       " u'sat': 7272,\n",
       " u'sxswmonster': 8260,\n",
       " u'holytrafficjams': 4094,\n",
       " u'letsdothis': 4952,\n",
       " u'15pm': 63,\n",
       " u'note': 5817,\n",
       " u'omfg': 5936,\n",
       " u'take': 8314,\n",
       " u'hollergram': 4088,\n",
       " u'wanting': 9187,\n",
       " u'coincide': 1789,\n",
       " u'mayer': 5311,\n",
       " u'handing': 3891,\n",
       " u'printer': 6589,\n",
       " u'opposite': 5982,\n",
       " u'knew': 4788,\n",
       " u'printed': 6588,\n",
       " u'pager': 6095,\n",
       " u'pages': 6098,\n",
       " u'cloudcamp': 1744,\n",
       " u'lawn': 4881,\n",
       " u'suxsw': 8184,\n",
       " u'average': 854,\n",
       " u'phil': 6287,\n",
       " u'drive': 2649,\n",
       " u'ways': 9220,\n",
       " u'link': 5005,\n",
       " u'salt': 7251,\n",
       " u'laws': 4882,\n",
       " u'lulling': 5143,\n",
       " u'cobra': 1775,\n",
       " u'surplus': 8169,\n",
       " u'imagines': 4286,\n",
       " u'hcsm': 3959,\n",
       " u'opportunism': 5980,\n",
       " u'bright': 1289,\n",
       " u'jaqueline': 4606,\n",
       " u'xml': 9481,\n",
       " u'slow': 7686,\n",
       " u'deck': 2292,\n",
       " u'wedig': 9253,\n",
       " u'going': 3688,\n",
       " u'hockey': 4080,\n",
       " u'roadie': 7157,\n",
       " u'assistant': 763,\n",
       " u'cursing': 2182,\n",
       " u'outlet': 6036,\n",
       " u'awaiting': 862,\n",
       " u'prime': 6581,\n",
       " u'resource': 7046,\n",
       " u'artist': 740,\n",
       " u'maps2': 5239,\n",
       " u'primo': 6583,\n",
       " u'borrow': 1217,\n",
       " u'worried': 9427,\n",
       " u'teachntech00': 8371,\n",
       " u'worries': 9428,\n",
       " u'where': 9287,\n",
       " u'xmas': 9480,\n",
       " u'fanbois': 3117,\n",
       " u'keyboard': 4733,\n",
       " u'cardless': 1475,\n",
       " u'dotco': 2603,\n",
       " u'indieauthors': 4362,\n",
       " u'impressions': 4316,\n",
       " u'surgery': 8167,\n",
       " u'ur': 8975,\n",
       " u'mecca': 5340,\n",
       " u'enlightening': 2884,\n",
       " u'untapped': 8946,\n",
       " u'jumped': 4693,\n",
       " u'bootleg': 1207,\n",
       " u'sites': 7623,\n",
       " u'goers': 3680,\n",
       " u'vaccines': 9017,\n",
       " u'wikitude': 9327,\n",
       " u'enjoys': 2883,\n",
       " u'oooorkut': 5963,\n",
       " u'verification': 9055,\n",
       " u'jobs': 4645,\n",
       " u'domo': 2571,\n",
       " u'farts': 3137,\n",
       " u'screen': 7351,\n",
       " u'battlela': 985,\n",
       " u'concentrate': 1874,\n",
       " u'awards': 866,\n",
       " u'spark': 7860,\n",
       " u'deliciously': 2319,\n",
       " u'ehphone': 2796,\n",
       " u'many': 5231,\n",
       " u'sxswedu': 8245,\n",
       " u'jeremie': 4627,\n",
       " u'workplace': 9417,\n",
       " u'fightthepaddle': 3219,\n",
       " u'backpack': 894,\n",
       " u'twit': 8830,\n",
       " u'compels': 1850,\n",
       " u'instaprint': 4435,\n",
       " u'njdoc': 5790,\n",
       " u'twin': 8829,\n",
       " u'anti': 606,\n",
       " u'3000': 136,\n",
       " u'mapquest': 5237,\n",
       " u'twig': 8827,\n",
       " u'caring': 1480,\n",
       " u'happydance': 3914,\n",
       " u'combines': 1811,\n",
       " u'west': 9273,\n",
       " u'locally': 5052,\n",
       " u'airlines': 467,\n",
       " u'bandcamp': 929,\n",
       " u'breath': 1274,\n",
       " u'prototype': 6656,\n",
       " u'wants': 9189,\n",
       " u'mekong': 5364,\n",
       " u'juts': 4706,\n",
       " u'quarantined': 6746,\n",
       " u'photos': 6299,\n",
       " u'hashtag': 3932,\n",
       " u'former': 3386,\n",
       " u'sit': 7620,\n",
       " u'engineering': 2876,\n",
       " u'longform': 5082,\n",
       " u'invoking': 4504,\n",
       " u'policies': 6431,\n",
       " u'newspaper': 5749,\n",
       " u'situation': 7627,\n",
       " u'ive': 4582,\n",
       " u'networkcircles': 5730,\n",
       " u'internets': 4468,\n",
       " u'wp7': 9443,\n",
       " u'purse': 6712,\n",
       " u'mixtape': 5494,\n",
       " u'bros': 1311,\n",
       " u'quiet': 6762,\n",
       " u'blah': 1132,\n",
       " u'ctrs': 2162,\n",
       " u'sxswbarcrawl': 8238,\n",
       " u'technology': 8397,\n",
       " u'fame': 3112,\n",
       " u'stpatrick': 8042,\n",
       " u'sxxpress': 8280,\n",
       " u'underestimate': 8897,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the .get() method and look up some words to see if they're in our vocabulary or not (if they are, .get() will return a number; if they aren't, it will return nothing). Notice anything interesting or surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9438"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(\"wouldn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've generated a vocabulary from our data, use the .transform() method to actually create the document-term matrix, supplying our text as an argument. Let's call the resulting matrix \"counts\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 168)\t1\n",
      "  (0, 427)\t1\n",
      "  (0, 769)\t2\n",
      "  (0, 2267)\t1\n",
      "  (0, 3944)\t1\n",
      "  (0, 4168)\t1\n",
      "  (0, 4525)\t1\n",
      "  (0, 4562)\t1\n",
      "  (0, 5703)\t1\n",
      "  (0, 6406)\t1\n",
      "  (0, 7146)\t1\n",
      "  (0, 7984)\t1\n",
      "  (0, 8228)\t1\n",
      "  (0, 8606)\t1\n",
      "  (0, 8823)\t1\n",
      "  (0, 8964)\t1\n",
      "  (0, 9202)\t1\n",
      "  (0, 9272)\t1\n",
      "  (1, 523)\t1\n",
      "  (1, 769)\t1\n",
      "  (1, 1448)\t1\n",
      "  (1, 2614)\t1\n",
      "  (1, 3367)\t1\n",
      "  (1, 4513)\t1\n",
      "  (1, 5814)\t1\n",
      "  :\t:\n",
      "  (8933, 6029)\t1\n",
      "  (8933, 6239)\t1\n",
      "  (8933, 6293)\t1\n",
      "  (8933, 7207)\t1\n",
      "  (8933, 7919)\t1\n",
      "  (8933, 8171)\t1\n",
      "  (8933, 8228)\t1\n",
      "  (8933, 8300)\t1\n",
      "  (8933, 8534)\t1\n",
      "  (8933, 9367)\t1\n",
      "  (8934, 521)\t1\n",
      "  (8934, 575)\t1\n",
      "  (8934, 3007)\t1\n",
      "  (8934, 3367)\t1\n",
      "  (8934, 3809)\t1\n",
      "  (8934, 4515)\t1\n",
      "  (8934, 6073)\t1\n",
      "  (8934, 6378)\t1\n",
      "  (8934, 6698)\t1\n",
      "  (8934, 7429)\t1\n",
      "  (8934, 7446)\t1\n",
      "  (8934, 8198)\t1\n",
      "  (8934, 8228)\t1\n",
      "  (8934, 8520)\t1\n",
      "  (8934, 8994)\t1\n"
     ]
    }
   ],
   "source": [
    "counts = count_vect.transform(text)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause here for a moment before continuing on to modeling\n",
    "\n",
    "After the group members have their data featurized, we'll talk for a bit about the machine learning approach we'll use in this lab: a Naive Bayes classifier.\n",
    "\n",
    "The math involved in Naive Bayes is a bit complex, but scikit-learn makes it easy to train and use a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and playing around with your model\n",
    "\n",
    "Now that we've imported MultinomialNB (a version of the classifier that can handle more than 2 labels), now we need to train it. This follows a two-step process very similar to what we did with CountVectorizer above: create a model instance, and then train it using the .fit() method. The only difference is that here, fit() will take TWO arguments -- counts and labels, in that order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MultinomialNB()\n",
    "model1.fit(counts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've got your model trained, try evaluating its predictions on some sentences. What does it get right? Can you trick it into being wrong? How?\n",
    "\n",
    "Here's a sample sentence to get you started. Just replace \"model1\" with the name of your trained model, and of course modify the sample sentence however you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "print(model1.predict(count_vect.transform([\"I love my iPhone!!\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring model accuracy\n",
    "\n",
    "Providing the model with sample sentences is fun, but it's not the best way to actually measure its performance. We need a large set of labeled data to really see how good the predictions are. Let's start by seeing how many of our tweets the model classifies correctly. As before, just replace \"model1\" with the name of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80861779518746502"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model1.predict(counts)\n",
    "sum(predictions == labels)/float(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test splits\n",
    "\n",
    "You probably got about 80% accuracy from that comparison. Not bad! -- unfortunately, though, we can't trust that number. We can't evaluate a model using the data it was trained on -- that'd be cheating, because it already knows the answers to those items!\n",
    "\n",
    "To start, let's take our data and divide it up into two parts, with about 80% of it for training our model and 80% for testing with. We have about 9000 rows of data to work with here, so let's train on the first 7500, and test on the rest. The code to create these subsets is included below for convenience; run it and then train and evaluate your model in the same way we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_train = counts[0:7500]\n",
    "counts_test = counts[7500:]\n",
    "labels_train = labels[0:7500]\n",
    "labels_test = labels[7500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MultinomialNB()\n",
    "model2.fit(counts_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65923344947735196"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = model2.predict(counts_test)\n",
    "sum(predictions2 == labels_test)/float(len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "\n",
    "Wow! Not as good as we thought, huh? Is our model even any good at all? One way to answer that is by comparing our accuracy to a \"baseline\", i.e. a simple model that makes dumb (but still principled) predictions. One popular baseline measure would be to just predict the most common label for everything! Let's try that and compare. Take the dummy model created below and evaluate it on our train-test split in the same way you did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_model = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59651567944250872"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.fit(counts_train, labels_train)\n",
    "dummy_predictions = dummy_model.predict(counts_test)\n",
    "sum(dummy_predictions == labels_test)/float(len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause here for a moment before continuing on to further evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Let's cross-validate a classifier on our data and see how it holds up.\n",
    "\n",
    "Below, create a new MultinomialNB instance, and then evaluate it using the cross_val_score() function. cross_val_score takes __4__ arguments: the model name, our \"counts\" and \"labels\" objects, and the number of iterations (or \"folds\") to use in the evaluation, in that order. The default number of folds is 3, but let's do 10 -- expressed as cv=10.\n",
    "\n",
    "Assign the result of cross_val_score to a variable name of your choosing, and print it. Then print it's average, obtained via the .mean() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65995526  0.62863535  0.62192394  0.64317673  0.68680089  0.71364653\n",
      "  0.69798658  0.66965286  0.62556054  0.6558296 ]\n",
      "0.660316826971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model3 = MultinomialNB()\n",
    "scores = cross_val_score(model3, counts, labels, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we got a bit lucky -- our average cross-validation accuracy is about the same as our original holdout. But it should still be clear why it's important to do this -- look at how much accuracy can vary from fold to fold!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Confusion Matrix\n",
    "\n",
    "As a first step towards understanding how to improve our model, let's take a closer look at what it's getting wrong. To do this, we look at the __confusion matrix__, which matches up the labels the model predicted against the labels things actually had. Here, we stick with our previous train-test split for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291 205   7]\n",
      " [180 643  33]\n",
      " [ 33  31  12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAEQCAYAAAD4eRwGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116812e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "sentiment_labels = ['positive', 'neutral', 'negative']\n",
    "cm = confusion_matrix(labels_test, predictions2, sentiment_labels)\n",
    "print(cm)\n",
    "fig = pl.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "pl.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + sentiment_labels)\n",
    "ax.set_yticklabels([''] + sentiment_labels)\n",
    "pl.xlabel('Predicted')\n",
    "pl.ylabel('True')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.58      0.58      0.58       503\n",
      "    neutral       0.73      0.75      0.74       856\n",
      "   negative       0.23      0.16      0.19        76\n",
      "\n",
      "avg / total       0.65      0.66      0.65      1435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels_test, predictions2, sentiment_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix reveals a big issue with our data, and a big issue in machine learning in general: __class imbalance__. We have ___way___ more Neutral items than anything else, and very few Negative items at all! It should be clear that better-represented labels are captured better by the model, and that less well-represented items frequently get misclassified with one of the more common labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more data!\n",
    "\n",
    "Fortunately, we happen to have some additional negative tweets lying around. They're not exactly from the same dataset, but a pretty similar one so maybe they'll help out. Read in the negative_tweet_supplement.csv file as a new data frame, split out the columns, and add them to our existing \"text\" and \"labels\" objects using the .append() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_negs = pd.read_csv(\"negative_tweet_supplement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_neg_text = new_negs['tweet_text']\n",
    "new_neg_labels = new_negs['tweet_sentiment']\n",
    "longer_text = text.append(new_neg_text)\n",
    "longer_labels = labels.append(new_neg_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, because we have changed our original text object, we need to re-fit it with CountVectorizer and create a new document-term matrix, as we did earlier. Do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.fit(longer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longer_counts = count_vect.transform(longer_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have added some more negative items to our data, let's redo our cross-validation with a new model, making sure to update the arguments in cross_val_score() to reflect any new variable names for our longer counts and labels objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61023622  0.5984252   0.57283465  0.69980315  0.76082677  0.78149606\n",
      "  0.76279528  0.74975369  0.71893491  0.74728529]\n",
      "0.700239121987\n"
     ]
    }
   ],
   "source": [
    "model4 = MultinomialNB()\n",
    "scores = cross_val_score(model4, longer_counts, longer_labels, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.read_csv(\"holdout_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout_tweets = holdout['tweet_text']\n",
    "holdout_labels = holdout['tweet_sentiment']\n",
    "\n",
    "holdout_counts = count_vect.transform(holdout_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(longer_counts, longer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_predictions = model4.predict(holdout_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53100000000000003"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(holdout_predictions == holdout_labels)/float(len(holdout_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61023622  0.5984252   0.57283465  0.69980315  0.76082677  0.78149606\n",
      "  0.76279528  0.74975369  0.71893491  0.74728529]\n",
      "0.700239121987\n"
     ]
    }
   ],
   "source": [
    "model5 = MultinomialNB()\n",
    "holdout_xval_scores = cross_val_score(model5, holdout_counts, holdout_labels, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Final bits: pipelines\n",
    "\n",
    "The last feature of scikit-learn we want to touch on, and a powerful resource for machine learning in general, is the pipeline. This does not introduce much new content as much as it presents a way of chaining together the various bits of data preparation and modeling we have done so far. This is really useful for iterating on your model development, and also highlights a great feature of scikit-learn which is the consistency of object types and methods shared across its various core functions.\n",
    "\n",
    "A couple new options are introduced here as well, without evaluation, as a way of getting you started on future work should you so choose. One of these is the ngram_count option within CountVectorizer -- this lets you include not just individual words, but word _sequences_, as features. That can be valuable -- think of the difference between \"Great!\" and \"Oh, great!\" (or even \"I like\" and \"I don't like\").\n",
    "\n",
    "The other is a feature selection step that comes before model training. Currently, every word in our vocabulary is considered as informative when training the model. That seems fair, but is it the best thing to do? What about words that only occur once in the data, and have no further predictive value? There's only so much probability to go around, and the often very large number of these rare features can diminish the power of other more important ones. Feature selection also helps to combat __overfitting__, where the model learns its training data __too__ well, and has trouble generalizing. (Of course, being too aggressive can yield the opposite problem of underfitting as well -- you wouldn't want to train a model on just one feature out of thousands!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = ['i', 'you', 'me', 'they', 'is', 'are', 'to', 'the', 'a', 'an', 'at', 'were', 'of', 'at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('counts', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "       ...i2 at 0x116545a28>)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "p = Pipeline(steps=[('counts', CountVectorizer(ngram_range = (1,2), lowercase=False)),\n",
    "                ('feature_selection', SelectKBest(chi2, k=6000)),\n",
    "                ('multinomialnb', MultinomialNB())])\n",
    "p.fit(longer_text, longer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout_preds = p.predict(holdout_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54525000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(holdout_preds == holdout_labels)/float(len(holdout_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional directions\n",
    "\n",
    "If you still have time (or want to keep working on this later!), there are several next steps you can consider playing around with. Here are a few suggestions to get you started.\n",
    "\n",
    "#### Try out a different model!\n",
    "\n",
    "Scikit-learn supports lots of different types of classifiers. You can find a list of them here, with links to more information about each: http://scikit-learn.org/stable/modules/multiclass.html. Much of the procedure you've learned fitting and evaluating Naive Bayes models will apply here as well.\n",
    "\n",
    "(Logistic regression and random forest are both popular options)\n",
    "\n",
    "#### Try out some new data!\n",
    "\n",
    "I've included three other sentiment datasets here for you to play around with, with different types of subject matter: politics, air travel, and sports. Lots of options here:\n",
    "\n",
    "* Repeating this modeling process on another dataset\n",
    "* Seeing how well our existing model performs on new, possibly unrelated data\n",
    "* Combining datasets in interesting ways to try and create the most robust model\n",
    "\n",
    "This is really core data science work here. A big challenge faced in machine learning is that models are only as good as the data they're trained on, and their performance often suffers when they're applied to new stuff. Our model here is trained mainly on tweets about the iPhone and other Apple products. How well does it capture discussions about other topics? Can these datasets be combined to yield better overall results? What are the tradeoffs in doing this?\n",
    "\n",
    "#### Go deep on model training and evaluation.\n",
    "\n",
    "We've noted at various points that there have been a lot of options you can play with when you're featurizing your data, and when you're training your model. You can revisit these and see what the effects are of not lowercasing your text, of including two- or three-word phrases along with single words, or tweaking the settings of your classifier (maybe you want to weight classes differently to address imbalance, or maybe you want to explore different assumptions about how your variables are distributed). Maybe you want to explore feature selection to help combat __overfitting__ (http://scikit-learn.org/stable/modules/feature_selection.html, SelectKBest is a good place to start). Some of these things might have a big impact. Some might not change very much at all. Welcome to the often-less-than-straightforward world of model optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
